{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cq9dFH2XdeN"
      },
      "source": [
        "<h2 align=\"center\"> Logistic Regression </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Br3LLX7XdeO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ26O_scXdeO"
      },
      "source": [
        "### Task 2: Load the Data and Libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('ex2data1.txt', header=None, names=['Exam 1 score', 'Exam 2 score', 'Admitted'])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "display(data.head())\n",
        "\n",
        "# Display information about the DataFrame, including data types and non-null values\n",
        "display(data.info())"
      ],
      "metadata": {
        "id": "8UgCOKhMZiF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-QYkG9h7Zh1S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dwCVyr7XdeP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMgXGqkGXdeQ"
      },
      "outputs": [],
      "source": [
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIcjZ7svXdeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09rDdwymXdeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLv7RfKvXdeQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epg17piGXdeR"
      },
      "source": [
        "### Task 3: Visualize the Data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwvaKA8qXdeR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDjtyhGyXdeR"
      },
      "source": [
        "### Task 4: Define the Logistic Sigmoid Function $\\sigma(z)$\n",
        "---\n",
        "\n",
        "$$ \\sigma(z) = \\frac{1}{1+e^{-z}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDNw0bL_XdeR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykatyrnoXdeR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7-hszTlXdeR"
      },
      "source": [
        "### Task 5: Compute the Cost Function $J(\\theta)$ and Gradient\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1kHNnm3XdeR"
      },
      "source": [
        "The objective of logistic regression is to minimize the cost function\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [ y^{(i)}log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)})log(1 - (h_{\\theta}(x^{(i)}))]$$\n",
        "\n",
        "where the gradient of the cost function is given by\n",
        "\n",
        "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-j5-nkOXdeR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmo9q94mXdeR"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CanYDqgyXdeS"
      },
      "source": [
        "### Task 6: Cost and Gradient at Initialization\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IjEC_xwXdeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgiGo-WtXdeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdD6dBLlXdeS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AinlqdIDXdeS"
      },
      "source": [
        "### Task 7: Gradient Descent\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0hCAwknXdeS"
      },
      "source": [
        "Minimize the cost function $J(\\theta)$ by updating the below equation and repeat until convergence\n",
        "$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$ (simultaneously update $\\theta_j$ for all $j$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-auc0aEXdeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87yFN343XdeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4ABm1psXdeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVvcdnrLXdeS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtHwTmZ9XdeS"
      },
      "source": [
        "### Task 8: Plotting the Convergence of $J(\\theta)$\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NR-x4nrXdeS"
      },
      "source": [
        "Plot $J(\\theta)$ against the number of iterations of gradient descent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JRr8cAlXdeS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6XG-w8pXdeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqaQYijaXdeT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eni6bgDVXdeT"
      },
      "source": [
        "### Task 9: Plotting the decision boundary\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0zdDT8DXdeT"
      },
      "source": [
        "$h_\\theta(x) = \\sigma(z)$, where $\\sigma$ is the logistic sigmoid function and $z = \\theta^Tx$\n",
        "\n",
        "When $h_\\theta(x) \\geq 0.5$ the model predicts class \"1\":\n",
        "\n",
        "$\\implies \\sigma(\\theta^Tx) \\geq 0.5$\n",
        "\n",
        "$\\implies \\theta^Tx \\geq 0$ predict class \"1\"\n",
        "\n",
        "Hence, $\\theta_1 + \\theta_2x_2 + \\theta_3x_3 = 0$ is the equation for the decision boundary, giving us\n",
        "\n",
        "$ x_3 = \\frac{-(\\theta_1+\\theta_2x_2)}{\\theta_3}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG0aH3qhXdeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzrYCtxgXdeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GzXtFJKXdeT"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl5ZTsK-XdeT"
      },
      "source": [
        "### Task 10: Predictions using the optimized $\\theta$ values\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e91e3WurXdeT"
      },
      "source": [
        "$h_\\theta(x) = x\\theta$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awiX5S6wXdej"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6ro3pyuXdej"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcTw5ssyXdej"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}